{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Artificiais\n",
    " **Nome: João Pedro Miranda Marques**\n",
    " \n",
    " **Matrícula: 2017050495** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio 4 - Perceptron Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Treinamento e vizualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Estimate Perceptron weights using stochastic gradient descent\n",
    "def train_perceptron(xin, yd, eta, tol, maxepocas, par):\n",
    "# xin : matriz Nxn com os dados de entrada\n",
    "# yd: r ́otulos de saída (0 ou 1)\n",
    "# eta : passo de treinamento\n",
    "# tol : tolerˆancia de erro\n",
    "# maxepocas: nu ́mero ma ́ximo de itera ̧co ̃es par : parˆametro de entrada .\n",
    "# # par=0 ==> xin tem dimens ̃ao n+1 e j ́a inclui\n",
    "# # entrada correspondente ao termo\n",
    "# # de polarizac ̧ ̃ao.\n",
    "# # par=1 ==> xin tem dimens ̃ao n e na ̃o inclui\n",
    "\n",
    "    dimxin = xin.shape  # Dimensões do conjunto de dados.\n",
    "    N = dimxin[0]       # Numero de amostras.\n",
    "    n = dimxin[1]       # Dimensao de entrada.\n",
    "\n",
    "    # Adiciona ou não um termo de polarização ao vetor de treinamento w.\n",
    "    if(par == 1):\n",
    "        wt = pd.DataFrame(rd.uniform(n+1) - 0.5).to_numpy() \n",
    "        xin = pd.concat(xin, axis=-1) # xin<−cbind(−1,xin)\n",
    "    else:\n",
    "        wt = pd.DataFrame(rd.uniform(n) - 0.5).to_numpy() \n",
    "\n",
    "    nepocas = 0 # Contador de epocas\n",
    "    eepoca = tol + 1 # Acumulador de erro de epocas\n",
    "    evec = [1][maxepocas] # Vetor de erros\n",
    "\n",
    "    # Laço principal de treinamento\n",
    "    while((nepocas < maxepocas) & (eepca > tol)):\n",
    "        ei2 = 0\n",
    "        #Sequencia aleatória de treinamento\n",
    "        xseq = rd.sample(N)\n",
    "        for i in N:\n",
    "            # Amostra dado da sequencia aleatória\n",
    "            irand = xseq[i]\n",
    "            # Calcula saída do Perceptron\n",
    "            yhati = 1* (np.dot(xin[irand ,], wt ) >= 0)\n",
    "            ei = yd[irand] - yhati\n",
    "            dw = eta * ei * xin[irand,]\n",
    "            # Ajusta vetor de pesos\n",
    "            wt = wt + dw\n",
    "            # Acumula erro por época\n",
    "            ei2 = ei2+ei*ei\n",
    "\n",
    "        # Incrementa número de épocas\n",
    "        nepocas = nepocas + 1\n",
    "        evec[nepocas] = ei2/N\n",
    "        # Armazena erro por época\n",
    "        eepoca = evec[nepocas]\n",
    "\n",
    "    # Retorna vetores de pesos e de erros\n",
    "    retlist = [wt, evec[1:nepocas]]\n",
    "\n",
    "    return retlist\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
